## Day 1 and 2
Following LOs should be covered:

- Enumerate the components of an ML pipeline
    - Reusable data exploration scripts
    - Reusable data prep
    - Reusable model training

- Build each component using standard python libraries:
    - Build reusable data exploration scripts
    - Build reusable data prep scripts
    - Build reusable model training scripts


## How to use the files?

You can create a new anaconda environment with relevant dependencies using the following commands

```shell
conda env create -f env.yaml
conda activate mlops
```
The instructor can start the discussion using [pre coded notebook](./notebooks/Data%20Scientist%20Notebook.ipynb). This has a sample code that a data scientist will generate. In the two days of discussion this notebook needs to be broken into [these scripts](./scripts/)


There is an [instructor notebook](./notebooks/D1.-D2ipynb) that can be used by the instructor to prepare the session.

A [student notebook](./notebooks/Learner_Notebook.ipynb) has a basic template that instructor can help a learner fill up.

Here is a brief description of the project structure

ğŸ“¦ml_operationalization
 â”£ ğŸ“‚assets
 â”ƒ â”£ ğŸ“‚data
 â”ƒ â”£ ğŸ“‚exploration
 â”ƒ â”£ ğŸ“‚inference
 â”ƒ â”£ ğŸ“‚model
 â”£ ğŸ“‚data
 â”ƒ â”£ ğŸ“œcredit.csv
 â”ƒ â”— ğŸ“œcredit_infer.csv
 â”£ ğŸ“‚images
 â”£ ğŸ“‚notebooks
 â”ƒ â”£ ğŸ“œD1-D2.ipynb
 â”ƒ â”£ ğŸ“œData Scientist Notebook.ipynb
 â”ƒ â”— ğŸ“œLearner_Notebook.ipynb
 â”£ ğŸ“‚scripts
 â”ƒ â”£ ğŸ“œexploration.py
 â”ƒ â”£ ğŸ“œinfer.py
 â”ƒ â”£ ğŸ“œprep.py
 â”ƒ â”£ ğŸ“œprep_infer.py
 â”ƒ â”— ğŸ“œtrain.py
 â”£ ğŸ“œenv.yaml
 â”— ğŸ“œwriteup.md 


 Notebooks contain the three notebooks
 1. D1-D2.ipynb (For instructor use)
 2. Data Scientist Notebook.ipynb (Learner and instructor use)
 3. Learner_Notebook.ipynb (Learner only, to be guided by instructor)

 The scripts directory contains the scripts to be created in the class. These have been build and described in the `D1-D2.ipynb`

 The assets directory will hold the assets generated by the ml pipeline go through `D1-D2.ipynb` for more detail.

 The `env.yaml` has the details in relevant python packages. You can use this to generate a conda environment to run the notebooks and scripts.

 The instructor is free to modify the contents and flow, this is an indicative guide on how to conduct the sessions.